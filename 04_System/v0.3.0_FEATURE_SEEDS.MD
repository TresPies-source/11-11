# v0.3.0 Premium Feature Seeds

**Purpose:** Knowledge base for generating Zenflow prompts  
**Date:** January 12, 2026  
**Status:** Seed Collection for v0.3.0 "Intelligence & Foundation"

---

## Seed 1: Supervisor Router (Agent Connect Pattern)

**Type:** Infrastructure Pattern  
**Research Source:** Dataiku Agent Connect

**Core Knowledge:**
- **Single Entry Point:** Supervisor is the only conversational interface; prevents agent sprawl
- **Description-Based Routing:** Uses LLM to read agent descriptions and select best fit (not keyword matching)
- **Cheap Routing Model:** GPT-4o-mini for cost-effective routing decisions
- **Confidence Threshold:** Fall back to default agent (Dojo) if confidence <0.6
- **Context Preservation:** Pass full Harness Trace and conversation history in handoffs
- **Handoff Patterns:** Dojo ↔ Librarian, Dojo ↔ Debugger (bidirectional)
- **Cost Tracking:** Track routing costs separately from agent execution costs
- **Fallback Logic:** Timeout after 5s, fall back on LLM failure, fall back if agent unavailable

**Agent Registry Schema:**
```json
{
  "id": "agent_id",
  "name": "Agent Name",
  "description": "What the agent does",
  "when_to_use": ["scenario 1", "scenario 2"],
  "when_not_to_use": ["scenario 1", "scenario 2"],
  "default": true|false
}
```

**API Endpoint:** `POST /api/supervisor/route`

**Excellence Criteria:**
- Stability: 10/10 (zero routing failures)
- Research Integration: 10/10 (pure Agent Connect)
- Depth: 10/10 (complete, extensible, documented)

**Revisit When:** Adding new agents to ecosystem, debugging routing accuracy

---

## Seed 2: Cost Guard (Three-Tier Budgeting)

**Type:** Cost Management Pattern  
**Research Source:** Dataiku Cost Guard

**Core Knowledge:**
- **Three Tiers:** Query-level, Session-level, User-level budgets
- **Per-Query Budget:** Estimate tokens before execution, warn at 80%, hard stop at 100%
- **Per-Session Budget:** Track cumulative tokens across conversation, warn/stop at thresholds
- **Per-User Budget:** Monthly tracking with rollover, warn/stop at thresholds
- **Pre-Flight Estimation:** Estimate token usage before LLM call (within 10% accuracy)
- **Cost-Aware Mode Selection:** Prefer cheaper modes (Mirror over Scout) when budget low
- **Budget Dashboard:** Real-time cost tracking UI with breakdown by query/session/user
- **Graceful Degradation:** Switch to cheaper models or modes when approaching limits

**Budget Thresholds:**
- Query: 10k tokens (warn at 8k, stop at 10k)
- Session: 50k tokens (warn at 40k, stop at 50k)
- User (monthly): 500k tokens (warn at 400k, stop at 500k)

**Cost Calculation:**
```
cost_usd = (prompt_tokens * input_price + completion_tokens * output_price) / 1M
```

**API Endpoints:**
- `POST /api/cost/estimate` - Pre-flight token estimation
- `GET /api/cost/budget` - Current budget status
- `POST /api/cost/track` - Log actual usage

**Excellence Criteria:**
- Stability: 10/10 (never exceeds budget)
- Research Integration: 10/10 (pure Cost Guard pattern)
- Depth: 10/10 (accurate estimation, user-friendly dashboard)

**Revisit When:** Budget exceeded, cost optimization needed, new pricing models

---

## Seed 3: Librarian Agent (Semantic Search & Retrieval)

**Type:** Agent Pattern  
**Research Source:** Dataiku Librarian (Connect + Analyze + Recommend)

**Core Knowledge:**
- **Three Capabilities:** Connect (search), Analyze (suggest), Recommend (retrieve)
- **Semantic Search:** Natural language queries via Supabase Vector (pgvector)
- **Embedding Model:** OpenAI `text-embedding-3-small` (cost-effective, high-quality)
- **Search Sources:** Seed patches, project memory (JOURNAL, task_plan, BUGS), artifacts, public prompts
- **Proactive Suggestions:** Analyze current Dojo session context, suggest relevant seeds
- **"Find Similar" Functionality:** Cosine similarity search for related prompts
- **Search UI:** Beautiful interface with filters (date, type, status), previews, and relevance scores
- **Indexing Pipeline:** Automatic indexing on create/update, batch indexing for existing content

**Search Algorithm:**
1. Generate embedding for user query
2. Cosine similarity search in pgvector
3. Rank by relevance score (>0.7 threshold)
4. Return top 5 results with context snippets

**API Endpoints:**
- `POST /api/librarian/search` - Semantic search
- `POST /api/librarian/suggest` - Proactive suggestions
- `POST /api/librarian/similar` - Find similar prompts
- `POST /api/librarian/index` - Index new content

**Excellence Criteria:**
- Stability: 10/10 (search never fails)
- Research Integration: 10/10 (pure Librarian pattern)
- Depth: 10/10 (fast, accurate, beautiful UI)
- Performance: 9/10 (search <1s)

**Revisit When:** Search relevance low, adding new search sources, optimizing performance

---

## Seed 4: Harness Trace (Nested JSON Logging)

**Type:** Observability Pattern  
**Research Source:** Dataiku Traceability

**Core Knowledge:**
- **Nested Spans:** Parent-child relationships create tree structure
- **Event Types:** MODE_TRANSITION, TOOL_INVOCATION, PERSPECTIVE_INTEGRATION, AGENT_HANDOFF, etc.
- **Span Schema:** `span_id`, `parent_id`, `event_type`, `timestamp`, `inputs`, `outputs`, `metadata`
- **Metadata:** Token counts, cost estimates, duration, model used, confidence scores
- **Storage:** Supabase (compressed JSON, indexed by session_id, user_id, timestamp)
- **Retrieval:** Fast queries (<500ms for full trace), pagination for large traces
- **Context Handoffs:** Harness Trace is the "context bus" for agent handoffs

**Span Example:**
```json
{
  "span_id": "span_001",
  "parent_id": null,
  "event_type": "MODE_TRANSITION",
  "timestamp": "2026-01-12T10:30:00Z",
  "inputs": {"mode": "Mirror", "perspectives": 3},
  "outputs": {"pattern": "Tension between speed and quality"},
  "metadata": {
    "tokens_used": 450,
    "cost_usd": 0.00045,
    "duration_ms": 1200,
    "model": "gpt-4o"
  }
}
```

**API Endpoints:**
- `POST /api/trace/log` - Log a span
- `GET /api/trace/:session_id` - Retrieve full trace
- `GET /api/trace/search` - Search traces by criteria

**Excellence Criteria:**
- Stability: 10/10 (logging never fails)
- Research Integration: 10/10 (pure traceability pattern)
- Depth: 10/10 (comprehensive, efficient, fast retrieval)

**Revisit When:** Debugging agent behavior, optimizing performance, auditing costs

---

## Seed 5: Hierarchical Context Management (4-Tier System)

**Type:** Context Optimization Pattern  
**Research Source:** Dataiku Context Iceberg

**Core Knowledge:**
- **Tier 1 (Always On):** Core system prompt, Dojo principles, current user query (~2k tokens)
- **Tier 2 (On Demand):** Active seed patches, relevant project memory (~5k tokens)
- **Tier 3 (When Referenced):** Full text of specific files or logs (~10k tokens)
- **Tier 4 (Pruned Aggressively):** General conversation history, less relevant details (~variable)
- **Budget-Aware Pruning:** Prune more aggressively when budget low (e.g., drop Tier 4, then Tier 3)
- **Pruning Algorithm:** Recency + relevance scoring, keep most recent + most relevant
- **Context Dashboard:** Real-time view of what's in context, token breakdown by tier
- **Token Reduction:** Target 30-50% reduction in token usage vs. flat context

**Pruning Rules:**
- Budget >80%: Include all tiers
- Budget 60-80%: Prune Tier 4 to last 5 messages
- Budget 40-60%: Prune Tier 4 to last 2 messages, Tier 3 to summaries only
- Budget <40%: Drop Tier 4 entirely, Tier 3 to summaries, Tier 2 to top 3 seeds

**API Endpoints:**
- `POST /api/context/build` - Build context for LLM call
- `GET /api/context/status` - Current context status
- `POST /api/context/prune` - Manual pruning trigger

**Excellence Criteria:**
- Stability: 10/10 (never loses critical context)
- Research Integration: 10/10 (pure Context Iceberg)
- Depth: 10/10 (intelligent pruning, transparent dashboard)
- Performance: 9/10 (reduces token usage 30-50%)

**Revisit When:** Context window errors, budget exceeded, optimizing token usage

---

## Seed 6: Safety Switch (Fallback to Conservative Mode)

**Type:** Error Handling Pattern  
**Research Source:** Dataiku Safety Switch

**Core Knowledge:**
- **Trigger Conditions:** LLM errors, API failures, parsing errors, conflicting perspectives, budget exhaustion
- **Conservative Mode:** Simplified Dojo mode with minimal LLM calls, basic reflection only
- **Graceful Degradation:** No hard failures, smooth transition to conservative mode
- **User Notification:** Clear messaging about why Safety Switch activated and how to recover
- **Recovery Path:** "Try again" button, "Switch back to normal mode" option
- **Logging:** All Safety Switch activations logged to Harness Trace with error details
- **Automatic Recovery:** Attempt to return to normal mode after 1 successful operation

**Conservative Mode Behavior:**
- Use cheaper model (GPT-4o-mini instead of GPT-4o)
- Limit to Mirror mode only (no Scout, Gardener, Implementation)
- Reduce context window (Tier 1 + Tier 2 only)
- Disable proactive suggestions
- Disable agent handoffs (Dojo only)

**API Endpoints:**
- `POST /api/safety/activate` - Activate Safety Switch
- `POST /api/safety/recover` - Attempt recovery
- `GET /api/safety/status` - Current safety status

**Excellence Criteria:**
- Stability: 10/10 (prevents catastrophic failures)
- Research Integration: 10/10 (pure Safety Switch pattern)
- Depth: 10/10 (smooth fallback, clear communication)
- Usability: 9/10 (user-friendly error handling)

**Revisit When:** Unexpected errors, budget issues, user confusion about failures

---

## Seed 7: DojoPacket Schema & Export

**Type:** Data Format Pattern  
**Research Source:** Dojo Protocol v1.0

**Core Knowledge:**
- **Portable Format:** Standardized JSON schema for session outputs
- **Complete Capture:** Session header, situation/stake, perspectives, assumptions, decisions, Next Move, artifacts
- **Export Formats:** JSON (machine-readable), Markdown (human-readable), PDF (professional)
- **One-Click Export:** "Copy DojoPacket" button in UI
- **Import Capability:** Resume session from imported packet
- **Share Links:** Generate shareable link to packet (optional, requires storage)
- **Packet History:** View all exported packets, re-export with updates

**Packet Schema:**
```json
{
  "version": "1.0",
  "session": {
    "id": "sess_abc123",
    "title": "Budget Planning",
    "stance": "Scout",
    "duration": 25,
    "created_at": "2026-01-12T10:00:00Z"
  },
  "situation": "I need to plan my budget for next month",
  "stake": "Avoid overspending and build savings",
  "perspectives": [
    "Income is variable, need buffer",
    "Fixed expenses are predictable",
    "Discretionary spending is the lever"
  ],
  "assumptions": {
    "known": ["Monthly income ~$5000"],
    "inferred": ["Rent is largest expense"],
    "unknown": ["Actual discretionary spending"]
  },
  "decisions": [
    "Use 50/30/20 rule as starting point",
    "Track discretionary spending for 1 week first"
  ],
  "keep_grow_compost_replant": {
    "keep": ["50/30/20 rule"],
    "grow": ["Track discretionary spending"],
    "compost": [],
    "replant": []
  },
  "next_move": "Set up spreadsheet with 50/30/20 categories",
  "artifacts": [
    {
      "type": "sheet",
      "title": "Budget Tracker",
      "url": "https://docs.google.com/spreadsheets/d/..."
    }
  ],
  "harness_trace_summary": {
    "total_spans": 12,
    "total_tokens": 4500,
    "total_cost_usd": 0.045,
    "duration_ms": 15000
  }
}
```

**API Endpoints:**
- `POST /api/packet/export` - Export DojoPacket
- `POST /api/packet/import` - Import DojoPacket
- `GET /api/packet/history` - Packet history

**Excellence Criteria:**
- Stability: 10/10 (export never fails)
- Research Integration: 10/10 (pure DojoPacket standard)
- Depth: 10/10 (complete schema, multiple formats, beautiful output)
- Usability: 9/10 (one-click export)

**Revisit When:** Sharing sessions, resuming work, exporting for external tools

---

## Seed 8: Agent Status & Activity Indicators

**Type:** UI Pattern  
**Research Source:** Transparency & Trust Patterns

**Core Knowledge:**
- **Agent Avatar:** Visual indicator of active agent (icon, color, animation)
- **Activity Messages:** "Librarian is searching..." "Dojo is reflecting..." "Supervisor is routing..."
- **Progress Indicators:** Animated progress bars for long operations (>2s)
- **Handoff Visualization:** Show transition between agents (fade out/in, breadcrumb trail)
- **Trace Breadcrumbs:** Show path through agents (Supervisor → Librarian → Dojo)
- **Cost Indicator:** Real-time token usage for current operation
- **Accessibility:** Screen reader support, keyboard navigation, WCAG AA compliance

**UI Components:**
- `AgentAvatar` - Icon + color + animation
- `ActivityMessage` - Text + icon + animation
- `ProgressBar` - Animated progress (indeterminate or determinate)
- `HandoffTransition` - Fade animation between agents
- `TraceBreadcrumbs` - Horizontal breadcrumb trail
- `CostIndicator` - Token count + cost estimate

**Animation Principles:**
- Smooth transitions (300ms ease-in-out)
- Subtle animations (no distracting motion)
- Purposeful motion (indicates progress or state change)
- 60fps performance (use CSS transforms, avoid layout thrashing)

**Excellence Criteria:**
- Beauty: 9/10 (smooth animations, polished)
- Usability: 10/10 (clear, helpful, accessible)
- Depth: 9/10 (complete, real-time, beautiful)

**Revisit When:** Adding new agents, improving user trust, debugging agent behavior

---

## Seed 9: Seed Patch Management UI

**Type:** UI Pattern  
**Research Source:** Dojo Protocol Memory Garden

**Core Knowledge:**
- **Seed Library:** Grid or list view of all seed patches with metadata
- **Keep/Grow/Compost/Replant:** Visual sorting interface (drag-and-drop or buttons)
- **Seed Search:** Search by name, type, content (semantic search via Librarian)
- **Seed Filters:** Filter by status (new/growing/mature/compost), type, date
- **Seed Details:** Modal or side panel with full seed content
- **Memory Patch Export:** Generate copyable Memory Patch for replanted seeds
- **Consent-Based Replanting:** User explicitly selects seeds to replant (max 2 per session)

**Seed Display Card:**
- Name (3-7 words)
- Type badge (principle, pattern, question, route, artifact, constraint)
- Status indicator (new, growing, mature, compost)
- "Why it matters" (1 line)
- "Revisit when" (trigger)
- Actions (View, Keep, Grow, Compost, Replant)

**Sorting Interface:**
- Drag-and-drop to quadrants (Keep/Grow/Compost/Replant)
- OR buttons on each card
- Bulk actions (select multiple, apply action)

**Excellence Criteria:**
- Beauty: 9/10 (smooth drag-and-drop, polished cards)
- Usability: 10/10 (intuitive, accessible)
- Depth: 9/10 (complete, fast, beautiful)

**Revisit When:** Managing seed patches, exporting Memory Patches, organizing knowledge

---

## Seed 10: Agent Registry UI

**Type:** UI Pattern  
**Research Source:** Transparency & Extensibility Patterns

**Core Knowledge:**
- **Agent Cards:** Visual cards for each agent (icon, name, description, status)
- **Agent Descriptions:** Clear "purpose, when to use, what it doesn't do"
- **Agent Status:** Online/offline, last used, usage stats (total queries, avg confidence)
- **Test Agent:** One-click test of agent routing (enter query, see which agent selected)
- **Edit Descriptions:** Admin UI for updating agent descriptions (JSON editor or form)
- **Registry Export:** Export registry as JSON (for backup or sharing)

**Agent Card Components:**
- Icon (agent avatar)
- Name (e.g., "Librarian Agent")
- Description (2-3 sentences)
- Status badge (online/offline)
- Usage stats (queries handled, avg confidence)
- Actions (Test, Edit, View Details)

**Test Agent Interface:**
- Input: User query
- Output: Selected agent, confidence, reasoning
- Comparison: Show all agents' scores (why this agent was selected)

**Excellence Criteria:**
- Beauty: 8/10 (polished agent cards)
- Usability: 9/10 (clear, intuitive, admin-friendly)
- Depth: 9/10 (complete, extensible, testable)

**Revisit When:** Adding new agents, debugging routing, updating descriptions

---

## Seed Usage Instructions

**For Zenflow:**
1. Read the relevant seed(s) before writing each prompt
2. Use seed knowledge to inform PRD and tech spec
3. Reference seed patterns in implementation
4. Self-assess against seed excellence criteria

**For Manus:**
1. Use seeds to validate Zenflow's implementation
2. Check that seed patterns are followed correctly
3. Verify excellence criteria are met
4. Update seeds if new patterns are discovered

---

**Author:** Manus AI (Dojo)  
**Status:** v0.3.0 Feature Seed Collection  
**Date:** January 12, 2026
